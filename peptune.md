# PepTune 优化方案

## 一、明确边界与设计原则

- **保持表示**：继续用 SMILES（可含环与修饰），不切到 SELFIES/图。
- **保持生成器主体**：RoFormer 去噪网络不大改，仅做轻量参数微调（LoRA/IA³ 可选）或完全冻结。
- **优化放在采样与评估侧**：把大部分创新放到 logit 成形（logit shaping）+ 约束 + 更高效的黑盒优化。
- **Oracle 仍是黑盒**：增强其效率与可靠性，而非推翻重做。

## 二、模型侧：无需重训或仅需极少微调的可落地改进

### 2.1 语法与环约束的前缀有穷自动机（FSA）解码（PCLS-FSA）

- **思想**：在每步去噪输出 logits 后，用一个基于 SMILES 文法与“环位数字平衡”的前缀约束器把非法 token 直接屏蔽（概率设为 −inf），再 softmax 采样。
- **实现**：
  - 维护状态：括号栈、环数字计数（0–9 的开闭配对）、价态上界（基于简单启发式，如避免明显超价键）。
  - 对环标记（1…9）强制“开闭配对”；若已用尽对应开口，不允许再次使用。
  - 对“强约束片段”（如肽键模板 N-C(=O) 相关片段）提供模板化闭包：当前缀落到危险分支，强制可行续写集合。
- **优点**：
  - 零训练成本，有效率地把“无效 SMILES”从源头掐掉，比靠 RDKit 事后无效惩罚更高效。
  - 可与你现有“键依赖掩蔽计划”配合：被保护 token 的候选集更窄、更稳。
- **新意**：把离散扩散与FSA 约束解码结合到肽的 SMILES 生成（含环与修饰）。

### 2.2 代价极低的前缀启发式奖励叠加（PCLS-Heuristics）

- **思想**：在每个时间步、每个候选 token 拼接后形成的前缀上，计算极快的可加启发式（无需 RDKit 构图），把它变成一个logit bonus 加回去噪 logits。
- **可用启发式**（全部 O(len(prefix)) 或 O(1) 累积）：
  - 氨基酸/片段配比：疏水/带电/芳香残基比例落在目标区间给正奖励；超界负奖励。
  - 简单不稳定模式黑名单：连续多个强亲电/亲核易出怪结构时降权。
  - 长度与封环进度：离目标长度更近、环尚未闭合则对闭环相关 token 加小额 bonus。
- **落地**：写一个 prefix_bonus(prefix, token)，输出可加到该 token 的 logit。计算快、不会拖慢扩散步。

### 2.3 温度与类别校准（Type-wise Temperature Scaling）

- 对不同token 类别（原子/环标记/支链/修饰标记）学习独立温度（或 logit 平移），在验证集的无效率/多样性上做网格搜索/贝叶斯优化即可。
- **优点**：一行代码级改动，常常显著降低“环位误选”与“支链爆炸”。

### 2.4 冻结生成器 + 极小“批评者/代理”网络作引导（Frozen-Critic Guidance, FCG）

- **思想**：不改 RoFormer 参数，单独训练一个非常小的前馈网络/轻量 Transformer（几十万到两百万参数），输入为去噪网络的中间隐表征或当前序列表示，输出若干 Oracle 的快速近似分。
- **训练数据**：用你现有生成器批量采样几万条片段/全序列，调用原 Oracle 打分作为标签来训练 Critic（离线，几小时级）。
- **采样时**：把 Critic 的分数梯度用作logit shaping（线性叠加或温度缩放）。
- **优点**：避免对主干重训；比 MCTS 便宜 1–2 个数量级；分数虽近似，但可显著提升平均质量。
- **新意**：离散扩散 + 冻结主干 + 小代理的后验引导（与“分类器自由引导”不同，不需标注条件）。

### 2.5 自监督“微调-校正器”二阶段（Self-Refine DAE）

- **思想**：保持原扩散采样 2–4 步得到候选，然后用一个小型 Masked DAE（仅对局部 token 蒙版重构）做 1–2 次迭代修正。
- **训练**：用扩散生成的样本作为“带噪输入”，目标是 RDKit 过检 + 基础规则 后的“最接近可行版本”（若无则跳过）。
- 只需小模型（如 2–4 层 RoFormer），训练成本低。
- **作用**：相当于“后校对器”，提升有效率与合成友好度，又不改变主干。

## 三、替换 MCTS：三种同等灵活但更快的黑盒优化器

全部作为 generate_*.py 的采样后端；生成器与 Oracle 接口不动。

### 3.1 交叉熵法（CEM-Diffusion）

- **做法**：每批次采样 N 条 → Oracle 打分 → 选前 K 条“精英” → 统计每步/每位 token 经验分布 → 作为下一批的 logit 修正（加权平滑）。循环 3–5 轮。
- **优点**：实现非常简单（几十行），自然并行，速度远快于树搜索，能稳定抬升帕累托前沿。
- **多目标**：采用切比雪夫标量化或随机权重多次运行，合并 ε-Pareto 集合。

### 3.2 质量-多样性（MAP-Elites-Diff）

- **做法**：定义 2–3 维“表型轴”（如长度、疏水度、净电荷）。对每个格子只保留该格子的最优个体。
- **作用**：天然产出覆盖更广的多样性，而单次 Oracle 峰值也能提升；非常适合多目标权衡演示。
- **成本**：和 CEM 类似，靠并行批采样堆吞吐，无树展开开销。

### 3.3 种子空间贝叶斯优化（Seed-BO）

- **做法**：把扩散初始噪声 z 经过固定低维投影（RFF/小 MLP），在这个 16–64 维“种子超参空间”上做 BO，目标是 Oracle。
- **优点**：无需改生成器/解码器；试验-评价循环快捷；对“找到单峰高分样本”有效。
- **新意**：第一次把噪声种子当作可优化超参，用 BO 驱动离散扩散的输出质量。

三者都比 MCTS 更好并行、代码量小；你可以在同一接口下切换比较，形成系统性方法学对比（亮点）。

## 四、Oracle 侧：可靠性与吞吐的工程级升级（论文也能写）

- **不确定性与集成**：对同一属性用
  - 小型集成（3–5 个轻模型）或
  - 单模型 + MC Dropout，
  把平均分作为目标、方差作为惩罚或重采样信号（高不确定 → 多生成几条）。

- **两级评价流水线**：
  - Level-0（极快）：前缀启发式 + 规则过滤，直接在解码步生效（见 2.2）。
  - Level-1（快）：基于片段/统计特征的轻 MLP（提前离线拟合真实 Oracle）。
  - Level-2（准）：原 Oracle（可能含 RDKit/深度模型）。
  在 CEM/MAP-Elites 中先用 L1 快筛，再用 L2 精检，整体吞吐 x3–x10。

- **缓存与向量化**：
  - 对确定性 Oracle做哈希缓存（SMILES canonical → hash）；
  - RDKit 尽量批处理与多进程，避免 Python GIL 阻塞；
  - 统一到 numpy/torch 张量化，降低 Python 循环开销。

## 五、任务迁移：不换表示与主干的三条“低门槛”扩展线

都保持 SMILES/修饰表达，主干 RoFormer 复用，主要变更在 Oracle 与后端优化器。

### 5.1 AMP/CPP/穿膜肽等功能肽家族

- **数据**：公共库（DBAASP, APD, Cell-penetrating peptide datasets 等）足够起步；只需把序列转 SMILES（已有流程）即可。
- **Oracle**：分类器（概率）+ 简单理化指标（长度、净电荷、疏水矩等）→ 多目标。
- **亮点**：和你的 PCLS-FSA/PCLS-Heuristics 配合，能显著降低无效率，加速大规模多目标探索。

### 5.2 靶向肽（与蛋白结合）

- **Oracle**：你已有 ESM2/cross-attn 亲和力预测模块可直接复用；对目标蛋白用冻结的 ESM2 表征，与生成肽的 1D 表征做轻量交互模型作为 L2 评分器；L1 用更快的序列学启发式。
- **新意**：把Frozen-Critic Guidance 训练成对“亲和力”最敏感的代理，引导采样；展示在速度/分数/多样性上的三者平衡。

### 5.3 环肽/主链修饰肽（维持 SMILES）

- **难点**：环位、配对、过价。
- **解决**：PCLS-FSA 的环数字配对 + 模板化闭环候选，大幅压缩非法环空间；自监督 DAE 负责“末端微修正”。
- **可比性**：和原 PepTune 在有效率/唯一性/环成功率上直观对比。

## 六、实验清单（一次成文，可发期刊）

每个模块都能做独立消融与组合实验，形成有说服力的表 1/表 2/图 2。

- **基线**：原 PepTune（SMILES + RoFormer + 键依赖掩蔽 + 无效损失 + MCTS）。
- **约束解码**：+ PCLS-FSA（无训练），看有效率↑、环错误↓、RDKit 失败率↓。
- **前缀启发式**：+ PCLS-Heuristics，看Oracle 平均分/Top-k 分↑与采样时间≈不变。
- **温度校准**：类别温度/平移扫描，报告有效率-多样性-分数的 Pareto。
- **黑盒优化替代**：MCTS vs CEM-Diffusion / MAP-Elites-Diff / Seed-BO：
  - 相同计算预算下的帕累托前沿、Top-1/Top-10 分数、样本/秒。
- **Frozen-Critic Guidance**：
  - 训练 1 个小 Critic，比较无 Critic vs 有 Critic在相同采样步下的收益；
  - 分析 Critic 误差与最终收益的相关性（可做一张有趣的相关散点图）。
- **Self-Refine DAE**：
  - “扩散 k 步 + 0/1/2 次 DAE 编辑”的有效率与 Oracle 分数变化。
- **多任务迁移**：
  - 选两类功能肽（如 AMP/CPP）与一类环肽；复用同一生成器，换 Oracle 与启发式，比较迁移成本与收益。
- **报告指标**：有效率、唯一性、内部多样性（平均 Tanimoto/Levenshtein）、构象/理化分布、Oracle 分数统计、帕累托面积、墙钟时间与GPU/CPU 利用率。

## 七、论文“创新点”可直接写法（供参考）

1. **PCLS-FSA**：提出面向肽-SMILES 的前缀有穷自动机约束解码，把文法与环配对纳入离散扩散的逐步采样，零训练成本地降低无效与过价错误。
2. **PCLS-Heuristics**：提出前缀启发式 logit 成形（基于肽学统计与环闭合进度），实现轻量级、可解释的目标引导。
3. **CEM/MAP-Elites/Seed-BO 采样后端**：系统化对比三类并行友好黑盒优化，显著优于 MCTS 的时间-质量折中。
4. **Frozen-Critic Guidance**：在冻结生成器前提下，训练小型代理网络近似 Oracle，实现后验学习的采样引导，无需条件标注或重训主干。
5. **Self-Refine DAE**：提出“扩散候选 + 小型 DAE 微编辑”的二阶段自校正，进一步提升有效率与合成友好度。

## 八、落地提示（工程与代码位点）

- 在 generate_mcts.py 旁新建：
  - generate_cem.py、generate_mapelites.py、generate_seedbo.py（共用 sampler_base.py）。
- constraints/fsa_smiles.py（实现状态机与 mask_logits(logits, state)）。
- heuristics/prefix_bonus.py（前缀启发式，返回 per-token bonus）。
- critic/critic_small.py（轻模型 + 训练脚本，输入 RoFormer 中间隐表征，输出多属性分）。
- dae/refiner.py（小型 RoFormer-DAE，mask-reconstruct 两三步即可）。
- 训练/推理参数层面加入：
  - --logit-calibration {per_class_temp}、--guidance {critic_weight}、--sampler {mcts|cem|map|bo}、--constraints on/off。
- Oracle 服务化：
  - oracle_server.py（多进程/批量队列），前端 evaluate(smiles_list)；开启缓存与快速/慢速两级评估。

## 九、风险与备选

- **FSA 过严可能损多样性**：可设置“软约束”（把被禁 token 设为极小负值而非 −inf），或按概率放宽环数字配对。
- **Critic 过拟合**：用在线重标注（每隔 N 轮从生成器新采样一批重训 1–2 个 epoch），保持近似分布一致。
- **CEM/Elites 局部最优**：
  - 初期加大温度与噪声，
  - 每轮引入 ε 比例的全新随机样本（探索），
  - Elites 中加入多样性惩罚（与已有解的 Levenshtein/Tanimoto 距离）。

## 一句话路线图（完全可行）

“不动主干 + 约束解码 + 轻量前缀引导 + 更快的并行黑盒优化 + 小代理引导 + 小型自校正器”
→ 显著提升有效率/Top-k 质量/帕累托前沿，推理时间大幅下降，且无需 SELFIES、无需重训大模型。
